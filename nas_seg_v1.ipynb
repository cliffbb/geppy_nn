{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "#from fastai.callbacks.hooks import *\n",
    "#from fastai.utils.mem import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "from gepcore.utils import convolution\n",
    "from gepcore.utils import cell_graph\n",
    "from gepcore.entity import Gene, Chromosome\n",
    "from gepcore.symbol import PrimitiveSet\n",
    "from nas_seg.seg_model import get_net, arch_config, Network\n",
    "from nas_seg.utils import code_to_rgb\n",
    "from nas_seg.isprs_dataset import ISPRSDataset, img_to_mask, mask_to_img\n",
    "from pygraphviz import AGraph\n",
    "import glob\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from skimage import io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"Great! Good to go!\")\n",
    "else:\n",
    "  print('CUDA is not up!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable torch backends\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "window_size = 128 \n",
    "\n",
    "msk_labels = np.array([\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"])\n",
    "num_classes = len(msk_labels) \n",
    "\n",
    "\n",
    "dataset = 'Vaihingen' #'Potsdam'\n",
    "dataset_dir = Path.home()/'rs_imagery/ISPRS-DATASETS/{}'.format(dataset)\n",
    "\n",
    "if dataset == 'Potsdam':\n",
    "    tiles = dataset_dir/'Ortho_IRRG/top_potsdam_{}_{}_IRRG.tif'\n",
    "    masks = dataset_dir/'Labels_for_participants/top_potsdam_{}_{}_label.tif'\n",
    "    e_masks = dataset_dir/'Labels_for_participants_no_Boundary/top_potsdam_{}_label_noBoundary.tif'\n",
    "    trainset_dir = dataset.lower() + '_{}'.format(window_size) \n",
    "    testset_ids = ['2_11', '2_12', '4_10', '5_11', '6_7', '7_8', '7_10']\n",
    "elif dataset == 'Vaihingen':\n",
    "    tiles = dataset_dir/'top/top_mosaic_09cm_area{}.tif'\n",
    "    masks = dataset_dir/'gts_for_participants/top_mosaic_09cm_area{}.tif'\n",
    "    e_masks = dataset_dir/'gts_eroded_for_participants/top_mosaic_09cm_area{}_noBoundary.tif'\n",
    "    trainset_dir = dataset.lower() + '_{}'.format(window_size) \n",
    "    testset_ids = ['5', '7', '23', '30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training set\n",
    "data_path = dataset_dir/'{}'.format(trainset_dir)\n",
    "img_path = data_path/'images/train'\n",
    "msk_path = data_path/'masks/train'\n",
    "#valid_path = data_path/'images/valid'\n",
    "\n",
    "get_mask = lambda x: msk_path/f'{x.stem}{x.suffix}'\n",
    "\n",
    "# img_dir = get_image_files(img_path)\n",
    "# img = img_dir[10]\n",
    "# msk = get_mask(img)\n",
    "# msk = PILImage.create(mask_to_img(io.imread(msk)))\n",
    "# img = PILImage.create(io.imread(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms = get_transforms()\n",
    "# data = (SegmentationItemList.from_folder(img_path)\n",
    "#         .split_by_rand_pct()\n",
    "#         .label_from_func(get_mask, classes=msk_labels)\n",
    "#         .transform(tfms, tfm_y=True, size=window_size[0])\n",
    "#         .databunch(bs=batch_size)\n",
    "#         .normalize(([0.4776, 0.3226, 0.3189], [0.1816, 0.1224, 0.1185])))\n",
    "\n",
    "# data\n",
    "\n",
    "data = DataBlock(blocks=(ImageBlock, MaskBlock(codes = msk_labels)),\n",
    "    get_items=get_image_files,\n",
    "    get_y=get_mask,\n",
    "    splitter=RandomSplitter(seed=42),\n",
    "    batch_tfms=[*aug_transforms(flip_vert=True, size=window_size), \n",
    "                Normalize.from_stats([0.4776, 0.3226, 0.3189], [0.1816, 0.1224, 0.1185])])\n",
    "\n",
    "dls = data.dataloaders(img_path, bs=10)\n",
    "\n",
    "#dls.show_batch()\n",
    "#([0.4769, 0.3227, 0.3191], [0.1967, 0.1358, 0.1300]) -- 256\n",
    "#[0.4776, 0.3226, 0.3189], [0.1816, 0.1224, 0.1185] -- 128\n",
    "#[0.4752, 0.3221, 0.3183], [0.1975, 0.1363, 0.1305]\n",
    "\n",
    "#.use_partial_data(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## # instantiate the network\n",
    "# net = SegNet()\n",
    "# define primitive set\n",
    "pset = PrimitiveSet('cnn')\n",
    "# add cellular encoding program symbols\n",
    "#pset.add_program_symbol(cell_graph.end)\n",
    "pset.add_program_symbol(cell_graph.seq)\n",
    "pset.add_program_symbol(cell_graph.cpo)\n",
    "pset.add_program_symbol(cell_graph.cpi)\n",
    "\n",
    "# add convolutional operations symbols\n",
    "conv_symbol = convolution.get_symbol()\n",
    "# pset.add_program_symbol(conv_symbol.conv1x1)\n",
    "# pset.add_program_symbol(conv_symbol.conv3x3)\n",
    "# pset.add_cell_symbol(conv_symbol.dwconv3x3)\n",
    "# pset.add_cell_symbol(conv_symbol.sepconv3x3)\n",
    "# pset.add_cell_symbol(conv_symbol.sepconv5x5)\n",
    "pset.add_cell_symbol(conv_symbol.dilconv3x3)\n",
    "pset.add_cell_symbol(conv_symbol.dilconv5x5)\n",
    "pset.add_cell_symbol(conv_symbol.conv3x3)\n",
    "# pset.add_cell_symbol(conv_symbol.conv1x1)\n",
    "# pset.add_cell_symbol(conv_symbol.dwconv3x3)\n",
    "# pset.add_cell_symbol(conv_symbol.maxpool3x3)\n",
    "# pset.add_cell_symbol(conv_symbol.avgpool3x3)\n",
    "\n",
    "def gene_gen():\n",
    "    return Gene(pset, 1)\n",
    "\n",
    "ch = Chromosome(gene_gen, 3)\n",
    "graph, comp_graphs = cell_graph.generate_comp_graph(ch)\n",
    "\n",
    "cell_graph.save_graph(graph, '../graphs/')\n",
    "cell_graph.draw_graph(graph, '../graphs/')\n",
    "\n",
    "conf = arch_config(comp_graphs=comp_graphs,\n",
    "                   channels=64,\n",
    "                   classes=num_classes)\n",
    "\n",
    "# net = get_net(conf)\n",
    "net = Network(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = [AGraph(g) for g in glob.glob('../graphs/*.dot')]\n",
    "_, comp_graphs = cell_graph.generate_comp_graph(graph)\n",
    "\n",
    "conf = arch_config(comp_graphs=comp_graphs, channels=64, classes=len(msk_labels))\n",
    "\n",
    "# net = get_net(conf)\n",
    "net = Network(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(preds, target, labels):\n",
    "    preds = preds.argmax(dim=1).cpu().numpy().ravel()\n",
    "    target = target.cpu().numpy().ravel()\n",
    "    return confusion_matrix(y_true=target, y_pred=preds, labels=labels) \n",
    "\n",
    "def overall_acc(preds, target, labels=range(num_classes)):\n",
    "    \"\"\"Calculate over accuracy\"\"\"\n",
    "    cm_ = cm(preds=preds, target=target, labels=labels) \n",
    "    acc = np.trace(cm_) / np.sum(cm_)\n",
    "    #print(torch.tensor(acc, device='cuda'))\n",
    "    return torch.tensor(acc, device='cuda')\n",
    "\n",
    "\n",
    "# def acc(preds, target, labels=msk_labels):\n",
    "#     \"\"\"Calculate over accuracy\"\"\"\n",
    "#     preds = preds.argmax(dim=1).cpu().numpy().ravel()\n",
    "#     target = target.cpu().numpy().ravel()\n",
    "    \n",
    "#     cm = confusion_matrix(y_true=target, y_pred=preds, labels=np.arange(len(labels)))\n",
    "#     ovacc = np.trace(cm) / np.sum(cm)\n",
    "#     print(torch.tensor(ovacc, device='cuda'))\n",
    "#     return torch.tensor(ovacc, device='cuda')\n",
    "\n",
    "# def overall_acc(input, target):\n",
    "#     target = target.squeeze(1)\n",
    "#     return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "\n",
    "metrics=overall_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_splitter(model):\n",
    "    return [params(model)[:132], params(model)[132:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = torch.tensor([[0.9]*5 + [1.1]]).cuda()\n",
    "# loss_func = CrossEntropyLossFlat(weight=weights, axis=1) \n",
    "\n",
    "save = SaveModelCallback(monitor='overall_acc')\n",
    "\n",
    "learn = Learner(dls, net, wd=1e-4, metrics=metrics, model_dir=dataset_dir, \n",
    "                cbs=save, splitter=model_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight = torch.ones(6) #cuda.FloatTensor([1.0, 1.431, 1.682, 1.435, 40.505, 649.216])\n",
    "# learn.lossfunc = CrossEntropyFlat(weight = weight)\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "# learn.fit_flat_cos(70, 1e-2)\n",
    "learn.fit_one_cycle(50, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# learn.create_opt()\n",
    "# learn.opt.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(dataset_dir/'stage_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(dataset_dir/'stage_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = [AGraph(g) for g in glob.glob('../graphs/*.dot')]\n",
    "_, comp_graphs = cell_graph.generate_comp_graph(graph)\n",
    "\n",
    "conf = arch_config(comp_graphs=comp_graphs, channels=64, classes=len(msk_labels))\n",
    "net = get_net(conf)\n",
    "\n",
    "\n",
    "tfms = get_transforms(do_flip=False)\n",
    "img_path = data_path/'images'\n",
    "msk_path = data_path/'masks/test'\n",
    "#print(img_path,'\\n', msk_path)\n",
    "\n",
    "bs = 30\n",
    "data = (SegmentationItemList.from_folder(img_path)\n",
    "       .split_by_folder(train='test', valid='test')\n",
    "       .label_from_func(get_mask, classes=msk_labels)\n",
    "       .transform(tfms, tfm_y=True, size=window_size[0])\n",
    "       .databunch(bs=bs)\n",
    "       .normalize(([0.4769, 0.3227, 0.3191], [0.1967, 0.1358, 0.1300])))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Learner(data, net, metrics=overall_acc, model_dir=dataset_dir).load('segnet')\n",
    "model.validate(data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.load(dataset_dir/'model_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/home/cliff/rs_imagery/ISPRS-DATASETS/Vaihingen/vaihingen_128_64')\n",
    "img_path = data_path/'images/test'\n",
    "msk_path = data_path/'masks/test'\n",
    "\n",
    "mask_labels = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] \n",
    "num_classes = len(mask_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "bs = 20\n",
    "tfms = transforms.Compose([transforms.ToTensor()])#[0.4769, 0.3227, 0.3191], [0.1967, 0.1358, 0.1300])])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_set = ISPRSDataset(img_path, msk_path, transforms=tfms)\n",
    "test_loader = DataLoader(test_set, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, loader, criterion):\n",
    "    \"\"\"Calculate accuracy with confusion matrix\"\"\"\n",
    "    total = len(loader)\n",
    "    n_labels = net.classes\n",
    "    acc = 0\n",
    "    val_loss = 0\n",
    "    net.eval()\n",
    "\n",
    "    for i, (imgs, true_masks), in enumerate(loader):\n",
    "        imgs = imgs.to(device='cuda', dtype=torch.float32)\n",
    "        true_masks = true_masks.to(device='cuda', dtype=torch.long)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            pred_masks = net(imgs)\n",
    "        \n",
    "        loss = criterion(pred_masks, true_masks)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        pred_masks = pred_masks.argmax(dim=1).cpu().numpy().ravel()\n",
    "        true_masks =true_masks.cpu().numpy().ravel()\n",
    "        cm = confusion_matrix(y_true=true_masks, y_pred=pred_masks, labels=range(n_labels))\n",
    "        acc +=  np.trace(cm) / np.sum(cm)\n",
    "\n",
    "    return acc/total, val_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = [AGraph(g) for g in glob.glob('../graphs/*.dot')]\n",
    "_, comp_graphs = cell_graph.generate_comp_graph(graph)\n",
    "\n",
    "conf = arch_config(comp_graphs=comp_graphs, channels=64, classes=len(msk_labels))\n",
    "net = get_net(conf)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(dataset_dir/'segnet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(net, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False)\n",
    "data = (SegmentationItemList.from_folder(img_path)\n",
    "        .split_by_rand_pct()\n",
    "        .label_from_func(get_mask, classes=msk_labels)\n",
    "        .transform(tfms, tfm_y=True, size=window_size[0])\n",
    "        .databunch(bs=batch_size)\n",
    "        .normalize(([0.4776, 0.3226, 0.3189], [0.1816, 0.1224, 0.1185])))\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Learner(data, net, metrics=overall_acc).load(dataset_dir/'model_0').split(lambda m: (m[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cb = SaveModelCallback(model, every='improvement', monitor='overall_acc', name='model_1')\n",
    "model.fit_one_cycle(12, slice(3e-3/400, 3e-3/4), pct_start=0.3, callbacks=[cb]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.train_ds[0][0]\n",
    "p = model.predict(img)\n",
    "img.show(y=learn.predict(img)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate(data.train_dl, metrics=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = [AGraph(g) for g in glob.glob('../graphs/*.dot')]\n",
    "_, comp_graphs = cell_graph.generate_comp_graph(graph)\n",
    "\n",
    "conf = arch_config(comp_graphs=comp_graphs, channels=64, classes=len(msk_labels))\n",
    "net = get_net(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Learner(data, model=net).load(dataset_dir/'model_0')\n",
    "model.export(dataset_dir/'export.pkl')\n",
    "model = load_learner(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = get_subRelu_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data,mode.cuda(),metrics=accuracy)\n",
    "learn.split(lambda m: m[4])\n",
    "#learn.fit_one_cycle(12,slice(1e-1,2.),pct_start=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_preds, labels=msk_labels):\n",
    "    \"\"\"Calculate over accuracy\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_preds, np.arange(len(labels)))\n",
    "    ovacc = np.trace(cm) / np.sum(cm)\n",
    "    return ovacc\n",
    "\n",
    "\n",
    "def metrics(y_true, y_preds, labels=msk_labels):\n",
    "    \"\"\"Calculate over accuracy, F1 score and Kappa coefficent\"\"\"\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_preds, np.arange(len(labels)))\n",
    "    gtotal = np.sum(cm)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    # compute overall accuracy\n",
    "    acc = np.trace(cm) / gtotal  #np.sum([cm[i][i] for i in np.arange(len(cm))])\n",
    "    print(\"{} pixels processed\".format(gtotal))\n",
    "    print(\"Accuracy : {:.6f}\".format(acc))\n",
    "    print(\"---------------------\")\n",
    "    \n",
    "    # compute F1 score\n",
    "    f1 = np.zeros(len(labels))\n",
    "    for i in np.arange(len(labels)):\n",
    "        try:\n",
    "            f1[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))\n",
    "        except:\n",
    "            # Ignore exception if there is no element in class i for test set\n",
    "            pass\n",
    "    print(\"F1 Score :\")\n",
    "    for i, score in enumerate(f1):\n",
    "        print(\"{}: {:.6f}\".format(labels[i], score))\n",
    "    print(\"-------------------\")\n",
    "        \n",
    "    # compute Kappa coefficient\n",
    "    pa = np.trace(cm) / gtotal\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / (gtotal * gtotal)\n",
    "    kappa = (pa - pe) / (1 - pe);\n",
    "    print(\"Kappa: {:.6f}\".format(kappa))\n",
    "    \n",
    "    return acc, f1, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, img_dir, step=step, window_size=window_size):\n",
    "    \n",
    "    all_preds = []\n",
    "    all_gts = []    \n",
    "    mb = master_bar(range(len(img_dir)))\n",
    "    \n",
    "    for i, fn in zip(mb, img_dir): \n",
    "        img = open_image(fn)\n",
    "        msk = open_mask(get_msk(fn))\n",
    "        emsk = open_mask(get_emsk(fn))\n",
    "\n",
    "        img = img.data.numpy().transpose((1,2,0))\n",
    "        pred = np.zeros(img.shape[:2]+(1,))\n",
    "        total = count_sliding_window(img, step=step, window_size=window_size)\n",
    "\n",
    "        for j, coords in progress_bar(enumerate(sliding_window(img, step=step, window_size=window_size)), \n",
    "                                            total=total, parent=mb):\n",
    "\n",
    "            x,y,w,h = coords\n",
    "            image_patches = np.copy(img[x:x+w, y:y+h]).transpose((2,0,1))\n",
    "            image_patches = torch.from_numpy(image_patches) \n",
    "            image_patches = image_patches.squeeze()\n",
    "\n",
    "            pred[x:x+w, y:y+h] = model.predict(Image(image_patches))[1].numpy().transpose((1,2,0))\n",
    "        \n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_gts.append(emsk.data.numpy().squeeze())\n",
    "\n",
    "        # display the img, true mask and predicted mask\n",
    "        print('Results for tile #{} with true mask and predicted mask')\n",
    "        fig = plt.figure()\n",
    "        fig.add_subplot(1,3,1)\n",
    "        plt.imshow(np.asarray(255*img, dtype='uint8'))\n",
    "        \n",
    "        fig.add_subplot(1,3,2)\n",
    "        plt.imshow(mask_to_img(msk.data.squeeze()))\n",
    "\n",
    "        fig.add_subplot(1,3,3)\n",
    "        plt.imshow(mask_to_img(pred.squeeze()))\n",
    "        plt.show()\n",
    "        \n",
    "        # compute metrics for each tile\n",
    "        metrics(pred.ravel(), emsk.data.numpy().squeeze().ravel())\n",
    "\n",
    "        print('================================')\n",
    "\n",
    "    # compute metrics for all the tiles\n",
    "    print('Overall evaluation results for all the tiles')\n",
    "    accuracy, _, _ = metrics(np.concatenate([p.ravel() for p in all_gts]).ravel(),\n",
    "                           np.concatenate([p.ravel() for p in all_preds]))\n",
    "\n",
    "    return accuracy, all_preds, all_gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.loss_func = torch.nn.CrossEntropyLoss(weight=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/cliff/rs_imagery/ISPRS-DATASETS/Vaihingen/vaihingen_png_format/images')\n",
    "img_path = path/'test'\n",
    "img_dir = get_files(img_path)\n",
    "\n",
    "get_msk = lambda x: str(x).replace(x.parts[-3], 'masks')\n",
    "get_emsk = lambda x: str(x).replace(x.parts[-3], 'masks').replace(x.parts[-2], ('e_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc, preds, gts = evaluate(model, img_dir, step=128, window_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1.0, 1.431, 1.682, 1.435, 40.505, 649.216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(top, step=32, window_size=(128,128)):\n",
    "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            yield x, y, window_size[0], window_size[1]\n",
    "            \n",
    "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Count the number of windows in an image \"\"\"\n",
    "    c = 0\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = get_files(mpath); mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk = get_mk(mg[1]); mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = open_image(mg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asarray(255*img_.data.numpy().transpose((1,2,0)), dtype='uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_sliding_window(img_.data.numpy().transpose((2,1,0)), step=64, window_size=(256,256)) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for tile, gt, gt_e in tqdm(zip(test_images, test_labels, eroded_labels), total=len(tile_ids)):\n",
    "\n",
    "#print(tile.shape)\n",
    "#total = count_sliding_window(tile, step=step, window_size=window_size) // batch_size\n",
    "step=64; window_size=(128, 128)\n",
    "img = img_.data.numpy().transpose((1,2,0))\n",
    "pred_ = np.zeros(img.shape[:2]+(1,))\n",
    "\n",
    "total = count_sliding_window(img, step=step, window_size=window_size) \n",
    "mb = master_bar(range(1))\n",
    "for i in mb:\n",
    "    #for batch, (data, target) in progress_bar(enumerate(trainset), total=len(trainset), parent=mb):\n",
    "    for j, coords in progress_bar(enumerate(sliding_window(img, step=step, window_size=window_size)), \n",
    "                                            total=total, parent=mb):\n",
    "\n",
    "        x,y,w,h = coords\n",
    "        image_patches = np.copy(img[x:x+w, y:y+h]).transpose((2,0,1))# for x,y,w,h in coords]\n",
    "        #image_patches = np.asarray(image_patches)\n",
    "        #print(image_patches.shape)\n",
    "\n",
    "        image_patches = torch.from_numpy(image_patches) #.cuda()\n",
    "        #print(image_patche.shape)\n",
    "\n",
    "        image_patches = image_patches.squeeze()\n",
    "\n",
    "        pred_[x:x+w, y:y+h] = net1.predict(Image(image_patches))[1].numpy().transpose((1,2,0))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pred_.squeeze() #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_to_img(p)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk = get_mk(mg[1]); \n",
    "mk = open_mask(mk)\n",
    "mk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_to_img(mk.data.squeeze())); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk.data.numpy().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, all_preds, all_gts = test(net.model, testset_ids[:1], step=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
